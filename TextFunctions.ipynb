{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "845a0a74",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-06T15:24:59.303931Z",
     "start_time": "2023-05-06T15:24:57.941809Z"
    }
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "import re\n",
    "import nltk\n",
    "import gensim\n",
    "from nltk.stem import SnowballStemmer   \n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from gensim.parsing.preprocessing import STOPWORDS\n",
    "from nltk.corpus import stopwords\n",
    "from spellchecker import SpellChecker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d5324e24",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-06T15:24:59.326796Z",
     "start_time": "2023-05-06T15:24:59.303931Z"
    }
   },
   "outputs": [],
   "source": [
    "# Custom Jupyter Progress Bar\n",
    "\n",
    "def log_progress(sequence, every=None, size=None, name='Items'):\n",
    "    from ipywidgets import IntProgress, HTML, VBox\n",
    "    from IPython.display import display\n",
    "\n",
    "    is_iterator = False\n",
    "    if size is None:\n",
    "        try:\n",
    "            size = len(sequence)\n",
    "        except TypeError:\n",
    "            is_iterator = True\n",
    "    if size is not None:\n",
    "        if every is None:\n",
    "            if size <= 200:\n",
    "                every = 1\n",
    "            else:\n",
    "                every = int(size / 200)     # every 0.5%\n",
    "    else:\n",
    "        assert every is not None, 'sequence is iterator, set every'\n",
    "\n",
    "    if is_iterator:\n",
    "        progress = IntProgress(min=0, max=1, value=1)\n",
    "        progress.bar_style = 'info'\n",
    "    else:\n",
    "        progress = IntProgress(min=0, max=size, value=0)\n",
    "    label = HTML()\n",
    "    box = VBox(children=[label, progress])\n",
    "    display(box)\n",
    "\n",
    "    index = 0\n",
    "    try:\n",
    "        for index, record in enumerate(sequence, 1):\n",
    "            if index == 1 or index % every == 0:\n",
    "                if is_iterator:\n",
    "                    label.value = '{name}: {index} / ?'.format(\n",
    "                        name=name,\n",
    "                        index=index\n",
    "                    )\n",
    "                else:\n",
    "                    progress.value = index\n",
    "                    label.value = u'{name}: {index} / {size}'.format(\n",
    "                        name=name,\n",
    "                        index=index,\n",
    "                        size=size\n",
    "                    )\n",
    "            yield record\n",
    "    except:\n",
    "        progress.bar_style = 'danger'\n",
    "        raise\n",
    "    else:\n",
    "        progress.bar_style = 'success'\n",
    "        progress.value = index\n",
    "        label.value = \"{name}: {index}\".format(\n",
    "            name=name,\n",
    "            index=str(index or '?')\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "99f41135",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-06T15:24:59.341516Z",
     "start_time": "2023-05-06T15:24:59.326796Z"
    }
   },
   "outputs": [],
   "source": [
    "# Function to get text in selective lowercase form\n",
    "\n",
    "def abbr_or_lower(word):\n",
    "    if re.match('([A-Z]+[a-z]*){2,}', word):\n",
    "        return word\n",
    "    else:\n",
    "        return word.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "17f617db",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-06T15:24:59.360546Z",
     "start_time": "2023-05-06T15:24:59.345276Z"
    }
   },
   "outputs": [],
   "source": [
    "# Function for different forms of tokeniztion\n",
    "\n",
    "def tokenize(words, modulation, lowercase='basic'):\n",
    "    tokens = re.split(r'\\W+', words)\n",
    "    stems = []\n",
    "    \n",
    "    # Get comprehensive set of stopwords\n",
    "    stop_words = STOPWORDS.union(set(stopwords.words('english'))) \n",
    "    \n",
    "    # filter out any tokens not containing letters (e.g., numeric tokens, raw punctuation)\n",
    "    for token in tokens:\n",
    "        \n",
    "        # All text as lowercase\n",
    "        if lowercase == 'basic':\n",
    "            lowers = abbr_or_lower(token).lower()\n",
    "        # Custom lowercase to allow all caps text for emphasis\n",
    "        else:\n",
    "            lowers = abbr_or_lower(token)\n",
    "            \n",
    "        if lowers not in stop_words:\n",
    "            if re.search('[a-zA-Z]', lowers):\n",
    "                \n",
    "                # Lowercase \n",
    "                if modulation == 0:\n",
    "                    stems.append(lowers)\n",
    "                    \n",
    "                # Stemming\n",
    "                if modulation == 1:\n",
    "                    porter = SnowballStemmer(\"english\")\n",
    "                    stems.append(porter.stem(lowers))\n",
    "                    \n",
    "                # Lemmatizing\n",
    "                if modulation == 2:\n",
    "                    lmtzr = WordNetLemmatizer()\n",
    "                    stems.append(lmtzr.lemmatize(lowers))\n",
    "                \n",
    "    return stems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b444705e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-06T15:24:59.375772Z",
     "start_time": "2023-05-06T15:24:59.361139Z"
    }
   },
   "outputs": [],
   "source": [
    "# Function to get list of unique words in text\n",
    "\n",
    "def unique_str(list_of_strings):\n",
    "    res = ()\n",
    "    for item in list_of_strings:\n",
    "        res = list(set(res) | set(item))\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fe1aa8ab",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-06T15:24:59.392346Z",
     "start_time": "2023-05-06T15:24:59.377201Z"
    }
   },
   "outputs": [],
   "source": [
    "# Function to get features using key words\n",
    "\n",
    "def get_feature(scraped_text, feature_list):\n",
    "    \n",
    "    empty_list = []\n",
    "    \n",
    "    # Loop through features to check for outdoor spaces\n",
    "    for i in scraped_text:\n",
    "        if len(set(i).intersection(feature_list)) == 0:\n",
    "            empty_list.append(0)\n",
    "        else:\n",
    "            empty_list.append(1)\n",
    "            \n",
    "    return empty_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e05573c4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-06T15:24:59.410093Z",
     "start_time": "2023-05-06T15:24:59.394295Z"
    }
   },
   "outputs": [],
   "source": [
    "# Function to find common words\n",
    "\n",
    "# text = cleaned text format of multiple corpora\n",
    "# hint = text to look for, string\n",
    "# method = text starting with hint, ends with hint, or hint in text\n",
    "\n",
    "def find_words(text, hint, method):\n",
    "    keywords = []\n",
    "    for i in text:\n",
    "        for j in i:\n",
    "            if method == 'startswith':\n",
    "                if j.startswith((hint)) == True:\n",
    "                    keywords.append(j)\n",
    "            if method == 'endswith':\n",
    "                if j.endswith((hint)) == True:\n",
    "                    keywords.append(j)\n",
    "            if method == 'in':\n",
    "                if hint in j:\n",
    "                    keywords.append(j)\n",
    "    return set(keywords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6896d5e7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-06T15:24:59.425662Z",
     "start_time": "2023-05-06T15:24:59.410917Z"
    }
   },
   "outputs": [],
   "source": [
    "# Spell Check\n",
    "\n",
    "def spell_check(text):\n",
    "    \n",
    "    # 'text' input is a string of text\n",
    "    \n",
    "    # Instantiate Spell Checker\n",
    "    spell = SpellChecker()\n",
    "    spell.word_frequency.add('km')\n",
    "    spell.word_frequency.add('vrt')\n",
    "    spell.word_frequency.add('dm')\n",
    "    \n",
    "    # Change text to list of strings\n",
    "    tokens = re.split(r'\\W+', text)\n",
    "    \n",
    "    list_of_words = []\n",
    "    \n",
    "    for token in tokens:\n",
    "        lowers = abbr_or_lower(token)\n",
    "        list_of_words.append(lowers)\n",
    "        \n",
    "    try:\n",
    "        list_of_words.remove('')\n",
    "    except:\n",
    "        pass\n",
    "        \n",
    "    # Identify misspelled text\n",
    "    misspelled = spell.unknown(list_of_words)\n",
    "\n",
    "    if len(misspelled) == 0:\n",
    "        text = text\n",
    "\n",
    "    else:\n",
    "        # Switch mispelled words with corrections\n",
    "        for word in misspelled:\n",
    "            corr = spell.correction(word)\n",
    "            text = text.replace(str(word), str(corr))\n",
    "            \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d5784d9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
